{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SỬ DỤNG YOLO PHÁT HIỆN ĐỐI TƯỢNG VÀ MOBILENET NHẬN DẠNG ĐỐI TƯỢNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import cv2 as cv\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import regularizers\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "import darknet\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các tham số \n",
    "# Initialize the parameters\n",
    "confThreshold = 0.5  # Confidence threshold\n",
    "nmsThreshold = 0.4  # Non-maximum suppression threshold\n",
    "inpWidth = 416  # Width of network's input image\n",
    "inpHeight = 416  # Height of network's input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load names of classes\n",
    "classesFile = \"../handSLT/data/obj.names\"\n",
    "classes = None\n",
    "##Đọc file tên đối tượng lưu vào classs###\n",
    "##1 YOUR CODE HERE##\n",
    "pass\n",
    "##END YOUR CODE##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng YOLO để phát hiện đối tượng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hand detection\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "modelConfiguration = \"../handSLT/cfg/yolo3_0_poses.cfg\"\n",
    "modelWeights = \"../handSLT/models/yolo3_0_poses_final.weights\"\n",
    "metafile =\"../handSLT/data/obj.data\"    \n",
    "### Load netMain=????\n",
    "##2 YOUR CODE HERE##\n",
    "pass\n",
    "##END YOUR CODE##\n",
    "\n",
    "\n",
    "### Load metaMain=????\n",
    "##3 YOUR CODE HERE##\n",
    "pass\n",
    "##END YOUR CODE##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng mobilenet để nhận dạng đối tượng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hand recognizer\n",
    "sys.path.insert(0, '../handSLT/mobilenet/')\n",
    "from mobilenet import MobileNetMod\n",
    "IMAGE_SIZE = 224  \n",
    "def preProcImg(img_array):\n",
    "  dim = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "  img_array = cv.resize(img_array, dim, interpolation=cv.INTER_AREA)\n",
    "  img_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "  return keras.applications.mobilenet.preprocess_input(img_expanded_dims)\n",
    "  \n",
    "classMap = {0: 'hand', 1: 'ok', 2: 'paper', 3: 'rock',\n",
    "            4: 'scissors', 5: 'the-finger', 6: 'thumbdown', 7: 'thumbup'}\n",
    "mnet = MobileNetMod(classMap)\n",
    "### Load mnet=????\n",
    "##4 YOUR CODE HERE##\n",
    "pass\n",
    "##END YOUR CODE##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xử lý dữ liệu đầu ra dự đoán để thể hiện trực quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "def write_log(x, y , w , h, classId,conf):\n",
    "  logfile = \"log_1120.txt\"\n",
    "  filel = open(logfile, \"a+\")\n",
    "  filel.write(\"{:4d}, {:.2f}, {:.2f}, {:.2f}, {:.2f}, {:2d},{:.2f}\\n\".format(int(fcount), \n",
    "               float(x), float(y), float(w), float(h), int(classId),float(conf)))\n",
    "  filel.close()\n",
    "def convertBack(x, y, w, h):\n",
    "    ### left, right, top, bottom =???\n",
    "    ##4 YOUR CODE HERE##\n",
    "    pass\n",
    "    ##END YOUR CODE##\n",
    "    return left, right, top, bottom    \n",
    "def postprocess(frame, outs,fcount):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    classname = 'hand'\n",
    "    min_W=16\n",
    "    min_H=32\n",
    "    for detection in outs:\n",
    "      if classname !=None and detection[0].decode()!=classname:\n",
    "        continue\n",
    "        ##x, y, w, h =???\n",
    "        ##5 YOUR CODE HERE##\n",
    "        pass\n",
    "        ##END YOUR CODE##\n",
    "      left, right, top, bottom = convertBack(\n",
    "            float(x), float(y), float(w), float(h))\n",
    "      drawPredMobileNet(left, top, right, bottom)\n",
    "\n",
    "def drawPredMobileNet(left, top, right, bottom):\n",
    "    X = []\n",
    "    origH = frame.shape[0]\n",
    "    origW = frame.shape[1]\n",
    "    newH = frame_resized.shape[0]\n",
    "    newW = frame_resized.shape[1]\n",
    "    \n",
    "    ratioH = origH/newH + 0.01\n",
    "    ratioW = origW/newW + 0.05\n",
    "    \n",
    "    if bottom > top and right > left:\n",
    "        origTop = int(top*ratioH)\n",
    "        origBottom = int(bottom*ratioH)\n",
    "        origleft = int(left*ratioW)\n",
    "        origright= int(right*ratioW)\n",
    "        roi = frame[origTop-10:origBottom+10, origleft-10:origright+10]\n",
    "        \n",
    "        if roi.shape[0] > 0 and roi.shape[1] > 0: \n",
    "          \n",
    "          roi = cv.cvtColor(roi, cv.COLOR_BGR2RGB)\n",
    "          cv.imshow(\"result\", roi)\n",
    "          cv.waitKey(10)\n",
    "          cv.imwrite(\"../handSLT/HandExtract/eval/aus-1-\" + str(fcount) + \".jpg\", roi)\n",
    "        #roi = frame_resized[top:bottom,left:right]\n",
    "        img_shape =(160, 120)\n",
    "        if roi.shape[0] > 0 and roi.shape[1] > 0:  \n",
    "          #img = preProcImg(roi)\n",
    "          #predictions = mnet.model.predict(img)\n",
    "          #maxInRows = np.amax(predictions, axis=1)\n",
    "          #res = np.where(predictions == maxInRows)\n",
    "          classId = 1\n",
    "          ##labels=???\n",
    "          ##6 YOUR CODE HERE##\n",
    "          pass\n",
    "          ##END YOUR CODE##\n",
    "        else:\n",
    "          label = 'hand'\n",
    "        if label == 'hand':\n",
    "          return\n",
    "        print(label)\n",
    "        cv.rectangle(frame_resized, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "        # Display the label at the top of the bounding box\n",
    "        labelSize, baseLine = cv.getTextSize(\n",
    "            label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        top = max(top, labelSize[1])\n",
    "        cv.rectangle(frame_resized, (left, top - round(1.5*labelSize[1])), (left + round(\n",
    "            1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)\n",
    "        cv.putText(frame_resized, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 1)\n",
    "        #write_log(left,top,right-left,bottom-top,classId,maxInRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện các bước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputvideo = \"aus1.mov\"\n",
    "cap = cv.VideoCapture(inputvideo)\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "print(round(cap.get(cv.CAP_PROP_FRAME_WIDTH)))\n",
    "darknet_image = darknet.make_image(darknet.network_width(netMain),\n",
    "                                   darknet.network_height(netMain),3)\n",
    "                                    \n",
    "fcount = 0;\n",
    "while (cap.isOpened()):\n",
    "    prev_time = time.time()\n",
    "    hasFrame, frame = cap.read()    \n",
    "    # Stop the program if reached end of video\n",
    "    if not hasFrame:\n",
    "        print(\"Done processing !!!\")\n",
    "        print(\"Output file is stored as \", outputFile)\n",
    "        cv.waitKey(3000)\n",
    "        # Release device\n",
    "        cap.release()\n",
    "        break\n",
    "    tick = time.process_time()    \n",
    "    if (fcount%5==0):\n",
    "      frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "      frame_resized = cv.resize(frame,\n",
    "                                     (darknet.network_width(netMain),\n",
    "                                      darknet.network_height(netMain)),\n",
    "                                     interpolation=cv.INTER_LINEAR)\n",
    "      darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())\n",
    "        #outs=???\n",
    "        ### Load metaMain=????\n",
    "        ##7 YOUR CODE HERE##\n",
    "        pass\n",
    "        ##END YOUR CODE##\n",
    "    # Remove the bounding boxes with low confidence\n",
    "        ### Load metaMain=????\n",
    "        ##8 YOUR CODE HERE##\n",
    "        pass\n",
    "        ##END YOUR CODE##\n",
    "    tock = time.process_time()    \n",
    "    t = time.time()-prev_time    \n",
    "    fcount = fcount+1\n",
    "    # Write the frame with the detection boxes\n",
    "    print(1.0/t)  \n",
    "cap.release()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
